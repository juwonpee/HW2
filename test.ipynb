{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dnf-Lp9ldeWs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.0.1) or chardet (4.0.0) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VQvgl5FWdwqF"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jdftyA0ueVQT"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('./Dataset.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('./dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AVwMBIX3bZKk"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('./drive/MyDrive/HW2/Dataset.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('./dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1zW6tExieJe",
        "outputId": "e6015c86-afce-434c-d9ab-5b5214216246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# import torch\n",
        "# import torch_directml\n",
        "# device = torch_directml.device()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UM_NPqTJdeWt"
      },
      "outputs": [],
      "source": [
        "# # # # Organize data into training and test datasets\n",
        "\n",
        "data_dir = './dataset'\n",
        "test_files = []\n",
        "\n",
        "# # Remove all previous datasets\n",
        "# isExist = os.path.exists(data_dir + \"/train\")\n",
        "# if isExist:\n",
        "#     shutil.rmtree(data_dir + \"/train\")\n",
        "#     os.mkdir(data_dir + \"/train\")\n",
        "# else:\n",
        "#     os.mkdir(data_dir + \"/train\")\n",
        "    \n",
        "# isExist = os.path.exists(data_dir + \"/test\")\n",
        "# if isExist:\n",
        "#     shutil.rmtree(data_dir + \"/test\")\n",
        "#     os.mkdir(data_dir + \"/test\")\n",
        "# else:\n",
        "#     os.mkdir(data_dir + \"/test\")\n",
        "\n",
        "# for x in range(10): # Loop 10 times for each class\n",
        "#     # split images into 8:2\n",
        "#     files = os.listdir(data_dir + \"/\" + str(x))\n",
        "#     train_files = files[:int(len(files)*0.8)]\n",
        "#     test_files = files[int(len(files)*0.8):int(len(files))]\n",
        "\n",
        "#       # copy to new path training\n",
        "    \n",
        "#     train_files_new = [None] * len(train_files)\n",
        "#     path = \"./dataset/train\" + \"/\" + str(x)\n",
        "\n",
        "#     isExist = os.path.exists(data_dir + \"/train/\" + str(x))\n",
        "#     os.mkdir(data_dir + \"/train/\" + str(x))\n",
        "#     if isExist:\n",
        "#       shutil.rmtree(data_dir + \"/train/\" + str(x))\n",
        "#       os.mkdir(data_dir + \"/train/\" + str(x))\n",
        "        \n",
        "\n",
        "#     for y in range(len(train_files)):\n",
        "#         print(data_dir + \"/\" + train_files[y])\n",
        "#         shutil.copyfile(data_dir + \"/\" + str(x) + \"/\" + train_files[y], path + \"/\" + train_files[y])\n",
        "\n",
        "\n",
        "    \n",
        "#     # copy to new path test\n",
        "    \n",
        "#     isExist = os.path.exists(data_dir + \"/test/\" + str(x))\n",
        "#     os.mkdir(data_dir + \"/test/\" + str(x))\n",
        "#     if isExist:\n",
        "#       shutil.rmtree(data_dir + \"/test/\" + str(x))\n",
        "#       os.mkdir(data_dir + \"/test/\" + str(x))\n",
        "\n",
        "#     test_files_new = [None] * len(test_files)\n",
        "#     path = \"./dataset/test\" + \"/\" + str(x)\n",
        "\n",
        "#     for y in range(len(test_files)):\n",
        "#         print(data_dir + \"/\" + test_files[y])\n",
        "#         shutil.copyfile(data_dir + \"/\" + str(x) + \"/\" + test_files[y], path + \"/\" + test_files[y])\n",
        "    \n",
        "  \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/juwonpee/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torchvision.datasets.folder.ImageFolder'>\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from avalanche.benchmarks import nc_benchmark\n",
        "from avalanche.benchmarks.utils import make_classification_dataset\n",
        "from avalanche.benchmarks.generators import filelist_benchmark, dataset_benchmark\n",
        "\n",
        "train_dataset = ImageFolder(data_dir+'/train', transform=ToTensor())\n",
        "test_dataset = ImageFolder(data_dir+'/test', transform=ToTensor())\n",
        "print(type(train_dataset))\n",
        "\n",
        "scenario_custom_task_labels = dataset_benchmark(\n",
        "    [train_dataset,train_dataset]\n",
        " \n",
        "   ,[test_dataset,test_dataset]\n",
        ")\n",
        "train_stream = train_dataset\n",
        "test_stream = test_dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define CNN\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(32*16*16, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 512)\n",
        "        self.fc3 = nn.Linear(512, 128)\n",
        "        self.fc4 = nn.Linear(128, 32)\n",
        "        self.fc5 = nn.Linear(32, 10)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "\n",
        "        x = x.view(-1, 32*16*16)\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc5(x)\n",
        "        x = torch.log_softmax(x, dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start of experience  0\n",
            "-- >> Start of training phase << --\n",
            "  6%|â–‹         | 51/800 [01:27<13:44,  1.10s/it]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m experience \u001b[39min\u001b[39;00m benchmark\u001b[39m.\u001b[39mtrain_stream:\n\u001b[1;32m     75\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStart of experience \u001b[39m\u001b[39m\"\u001b[39m, experience\u001b[39m.\u001b[39mcurrent_experience)\n\u001b[0;32m---> 76\u001b[0m         strategy\u001b[39m.\u001b[39;49mtrain(experience)\n\u001b[1;32m     78\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining completed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mComputing accuracy on the whole test set\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/avalanche/training/templates/base_sgd.py:146\u001b[0m, in \u001b[0;36mBaseSGDTemplate.train\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    140\u001b[0m           experiences: Union[CLExperience,\n\u001b[1;32m    141\u001b[0m                              ExpSequence],\n\u001b[1;32m    142\u001b[0m           eval_streams: Optional[Sequence[Union[CLExperience,\n\u001b[1;32m    143\u001b[0m                                                 ExpSequence]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    144\u001b[0m           \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 146\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtrain(experiences, eval_streams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluator\u001b[39m.\u001b[39mget_last_metrics()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/avalanche/training/templates/base.py:116\u001b[0m, in \u001b[0;36mBaseTemplate.train\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperience \u001b[39min\u001b[39;00m experiences:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_before_training_exp(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_exp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperience, eval_streams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    117\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_training_exp(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_training(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/avalanche/training/templates/base_sgd.py:264\u001b[0m, in \u001b[0;36mBaseSGDTemplate._train_exp\u001b[0;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop_training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_epoch(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_training_epoch(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/avalanche/training/templates/update_type/sgd_update.py:28\u001b[0m, in \u001b[0;36mSGDUpdate.training_epoch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion()\n\u001b[1;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_before_backward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 28\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_backward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     31\u001b[0m \u001b[39m# Optimization step\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/avalanche/training/templates/base_sgd.py:200\u001b[0m, in \u001b[0;36mBaseSGDTemplate.backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    199\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run the backward pass.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss\u001b[39m.\u001b[39;49mbackward()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from avalanche.benchmarks.classic import SplitCIFAR10\n",
        "from avalanche.benchmarks.generators import nc_benchmark\n",
        "from avalanche.models import SimpleMLP, as_multitask\n",
        "from avalanche.training.supervised import Naive, LwF, GDumb, AGEM, EWC, JointTraining\n",
        "import torch.optim as optim\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from avalanche.training.plugins import ReplayPlugin, CoPEPlugin, EvaluationPlugin\n",
        "\n",
        "\n",
        "# model = SimpleMLP(input_size=32 * 32 * 3, num_classes=10)\n",
        "# model = as_multitask(model, \"classifier\")\n",
        "model = CNN()\n",
        "\n",
        "\n",
        "    # Prepare for training & testing\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "\n",
        "benchmark = nc_benchmark(train_dataset=train_stream, test_dataset=test_stream, n_experiences=5,task_labels=True, class_ids_from_zero_in_each_exp=True)\n",
        "\n",
        "\n",
        "# benchmark = SplitCIFAR10(\n",
        "#         n_experiences=5,\n",
        "#         return_task_id=True,\n",
        "#         class_ids_from_zero_in_each_exp=True,\n",
        "# )  \n",
        "\n",
        "# Choose a CL strategy\n",
        "# LwF\n",
        "# strategy = LwF(\n",
        "#         model=model,\n",
        "#         optimizer=optimizer,\n",
        "#         criterion=criterion,\n",
        "#         alpha=1,\n",
        "#         temperature=1,\n",
        "#         train_epochs=3,\n",
        "#         train_mb_size=128,\n",
        "#         eval_mb_size=128,\n",
        "#         device=device,\n",
        "#         plugins=[ReplayPlugin(mem_size=10000)],\n",
        "#     )\n",
        "\n",
        "# # Naive with replay\n",
        "# strategy = Naive(\n",
        "#         model=model,\n",
        "#         optimizer=optimizer,\n",
        "#         criterion=criterion,\n",
        "#         train_mb_size=128,\n",
        "#         train_epochs=10,\n",
        "#         eval_mb_size=128,\n",
        "#         device=device,\n",
        "#         plugins=[ReplayPlugin(mem_size=10000)],\n",
        "#     )\n",
        "\n",
        "\n",
        "# AGEM\n",
        "# from avalanche.training.plugins import EvaluationPlugin\n",
        "# from avalanche.logging import InteractiveLogger\n",
        "# from avalanche.evaluation.metrics import (\n",
        "#     forgetting_metrics,\n",
        "#     accuracy_metrics,\n",
        "#     loss_metrics,\n",
        "# )\n",
        "# interactive_logger = InteractiveLogger()\n",
        "# eval_plugin = EvaluationPlugin(\n",
        "#       accuracy_metrics(\n",
        "#           minibatch=True, epoch=True, experience=True, stream=True\n",
        "#       ),\n",
        "#       loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "#       forgetting_metrics(experience=True),\n",
        "#       loggers=[interactive_logger],\n",
        "# )\n",
        "\n",
        "# strategy = AGEM(\n",
        "#             model,\n",
        "#             optimizer,\n",
        "#             criterion,\n",
        "#             256, #args.patterns_per_exp,\n",
        "#             256, #args.sample_size,\n",
        "#             train_epochs= 5,#args.epochs,\n",
        "#             device=device,\n",
        "#             train_mb_size=128,\n",
        "#             eval_mb_size=128,\n",
        "#             evaluator=eval_plugin,\n",
        "#         )\n",
        "\n",
        "# strategy = JointTraining(\n",
        "#         model=model,\n",
        "#         optimizer=optimizer,\n",
        "#         criterion=criterion,\n",
        "#         train_mb_size=128,\n",
        "#         train_epochs=5,\n",
        "#         eval_mb_size=128,\n",
        "#         device=device,\n",
        "#     )\n",
        "# strategy.train(benchmark.train_stream)\n",
        "# strategy.eval(benchmark.test_stream)\n",
        "\n",
        "# # EWC\n",
        "# strategy = EWC(\n",
        "#         model=model,\n",
        "#         optimizer=optimizer,\n",
        "#         criterion=criterion,\n",
        "#         0.4, #args.ewc_lambda,\n",
        "#         \"separate\" #args.ewc_mode,\n",
        "#         decay_factor=0.1\n",
        "#         train_epochs=1,\n",
        "#         device=device,\n",
        "#         train_mb_size=128,\n",
        "#         eval_mb_size=128\n",
        "          # mem_size=50000,\n",
        "#     )\n",
        "\n",
        "# # GDumb\n",
        "strategy = GDumb(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "        train_mb_size=128,\n",
        "        eval_mb_size=128,\n",
        "        train_epochs=1,\n",
        "        eval_every=0,\n",
        "        device=device,\n",
        "        mem_size=50000,\n",
        ")\n",
        "\n",
        "# train and test loop\n",
        "for experience in benchmark.train_stream:\n",
        "        print(\"Start of experience \", experience.current_experience)\n",
        "        strategy.train(experience)\n",
        "        \n",
        "        print(\"Training completed\")\n",
        "\n",
        "        print(\"Computing accuracy on the whole test set\")\n",
        "        strategy.eval(benchmark.test_stream)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
