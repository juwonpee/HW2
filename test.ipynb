{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "Dnf-Lp9ldeWs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "VQvgl5FWdwqF"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "jdftyA0ueVQT"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('./Dataset.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('./dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "AVwMBIX3bZKk"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('./drive/MyDrive/HW2/Dataset.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('./dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1zW6tExieJe",
        "outputId": "e6015c86-afce-434c-d9ab-5b5214216246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "UM_NPqTJdeWt"
      },
      "outputs": [],
      "source": [
        "# # # Organize data into training and test datasets\n",
        "\n",
        "data_dir = './dataset'\n",
        "test_files = []\n",
        "\n",
        "\n",
        "# # Remove all previous datasets\n",
        "# for x in range(5):\n",
        "#     isExist = os.path.exists(data_dir + \"/train\" + str(x))\n",
        "#     if isExist:\n",
        "#         shutil.rmtree(data_dir + \"/train\" + str(x))\n",
        "#     isExist = os.path.exists(data_dir + \"/test\" + str(x))\n",
        "#     if isExist:\n",
        "#         shutil.rmtree(data_dir + \"/test\" + str(x))\n",
        "\n",
        "# for x in range(10): # Loop 10 times for each class\n",
        "#     # split images into 8:2\n",
        "#     files = os.listdir(data_dir + \"/\" + str(x))\n",
        "#     train_files = files[:int(len(files)*0.8)]\n",
        "    \n",
        "#     train_files_new = [None] * len(train_files)\n",
        "#     path = \"./dataset/train\" + str(int(x/2)) +  \"/\" + str(x)\n",
        "    \n",
        "#     # Create directory if not created\n",
        "#     isExist = os.path.exists(path)\n",
        "#     if not isExist:\n",
        "#         os.makedirs(path)\n",
        "        \n",
        "#     # copy to new path\n",
        "#     for y in range(len(train_files)):\n",
        "#         print(data_dir + \"/\" + str(x) + \"/\" + train_files[y])\n",
        "#         shutil.copyfile(data_dir + \"/\" + str(x) + \"/\" + train_files[y], path + \"/\" + train_files[y])\n",
        "    \n",
        "        \n",
        "#     # same but for test images\n",
        "#     test_files = files[int(len(files)*0.8):len(files)]\n",
        "#     test_files_new = [None] * int(len(test_files)/5)\n",
        "    \n",
        "#     for y in range(5): # Loop for each dataset\n",
        "#         test_file_dataset = test_files[y*int(len(test_files)/5):(y+1)*int(len(test_files)/5)]\n",
        "#         path = \"./dataset/test\" + str(y) + \"/\" + str(x)\n",
        "        \n",
        "#         # Create directory if not created\n",
        "#         isExist = os.path.exists(path)\n",
        "#         if not isExist:\n",
        "#             os.makedirs(path)\n",
        "            \n",
        "#         for z in range(len(test_file_dataset)):\n",
        "#             print(data_dir + \"/\" + str(x) + \"/\" + test_files[y])\n",
        "#             shutil.copyfile(data_dir + \"/\" + str(x) + \"/\" + test_files[z], path + \"/\" + test_files[z])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xpjTiUjdeWu"
      },
      "source": [
        "##### Check if training dataset is correctly created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "QvQeipwpdeWv",
        "outputId": "e0cd2beb-a8ce-42b5-8bd4-a1ed412f84d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "8000\n",
            "['0', '1']\n",
            "2000\n",
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "1\n",
            "8000\n",
            "['2', '3']\n",
            "2000\n",
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "2\n",
            "8000\n",
            "['4', '5']\n",
            "2000\n",
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "3\n",
            "8000\n",
            "['6', '7']\n",
            "2000\n",
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "4\n",
            "8000\n",
            "['8', '9']\n",
            "2000\n",
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_dataset = [None] * 5\n",
        "test_dataset = [None] * 5\n",
        "for x in range(5):\n",
        "    print(x)\n",
        "    train_dataset[x] = ImageFolder(data_dir+'/train'+str(x), transform=ToTensor())\n",
        "    print(len(train_dataset[x]))\n",
        "    print(train_dataset[x].classes)\n",
        "    test_dataset[x] = ImageFolder(data_dir+'/test'+str(x), transform=ToTensor())\n",
        "    print(len(test_dataset[x]))\n",
        "    print(test_dataset[x].classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcoo65xbdeWx"
      },
      "source": [
        "##### Create validation set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "HPFJymc5deWx"
      },
      "outputs": [],
      "source": [
        "# # Set seed to always create the same validation set\n",
        "# import torch\n",
        "\n",
        "# torch.manual_seed(10)\n",
        "\n",
        "# val_size_ratio = 0.1\n",
        "# val_size = int(len(train_dataset[0]) * val_size_ratio)\n",
        "# val_dataset = [None] * 5\n",
        "\n",
        "# for x in range(5):\n",
        "#     train_size = len(train_dataset[x]) - val_size\n",
        "\n",
        "#     train_dataset[x], val_dataset[x] = random_split(train_dataset[x], [train_size, val_size])\n",
        "#     print(len(train_dataset[x]), len(val_dataset[x]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt8_-9gHdeWy"
      },
      "source": [
        "##### Create dataloader object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "3EkVDRyodeWy",
        "outputId": "664caa2b-2295-40ef-c77a-0b352d73a894",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "tensor([1, 1, 1, 1, 0, 1, 0, 0])\n",
            "tensor([4, 9, 0, 6, 6, 4, 7, 3])\n",
            "1\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([6, 4, 9, 1, 2, 4, 2, 4])\n",
            "2\n",
            "tensor([0, 1, 0, 0, 1, 1, 1, 0])\n",
            "tensor([5, 0, 3, 6, 0, 7, 1, 6])\n",
            "3\n",
            "tensor([0, 1, 1, 1, 1, 1, 0, 1])\n",
            "tensor([7, 5, 0, 1, 7, 3, 4, 5])\n",
            "4\n",
            "tensor([1, 0, 1, 0, 0, 1, 1, 1])\n",
            "tensor([0, 2, 8, 8, 5, 9, 4, 0])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "batch_size=8\n",
        "\n",
        "train_dataload = [None]*5\n",
        "test_dataload = [None]*5\n",
        "val_dataload = [None]*5\n",
        "for x in range(5):\n",
        "    print(x)\n",
        "    train_dataload[x] = DataLoader(train_dataset[x], batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    data_iter = iter(train_dataload[x])\n",
        "    images, labels = next(data_iter)\n",
        "    print(labels)\n",
        "    test_dataload[x] = DataLoader(test_dataset[x], batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    data_iter = iter(test_dataload[x])\n",
        "    images, labels = next(data_iter)\n",
        "    print(labels)\n",
        "    # val_dataload[x] = DataLoader(val_dataset[x], batch_size, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "CasvkxCCdeWz"
      },
      "outputs": [],
      "source": [
        "# from torchvision.utils import make_grid\n",
        "\n",
        "# def show_batch(dl):\n",
        "#     for images, labels in dl:\n",
        "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
        "#         ax.set_xticks([]); ax.set_yticks([])\n",
        "#         ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
        "#         plt.show()\n",
        "#         print('Class: ', ' '.join(f'{labels[j]:5}' for j in range(batch_size)))\n",
        "#         break\n",
        "\n",
        "# for x in range(5):\n",
        "#     print(\"Dataset: \" + str(x))\n",
        "#     print(\"train\")\n",
        "#     show_batch(train_dataload[x])\n",
        "#     print(\"test\")\n",
        "#     show_batch(test_dataload[x])\n",
        "#     # print(\"validation\")\n",
        "#     # show_batch(val_dataload[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "yUbRPJD6deW0"
      },
      "outputs": [],
      "source": [
        "# define CNN\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(32*16*16, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 512)\n",
        "        self.fc3 = nn.Linear(512, 128)\n",
        "        self.fc4 = nn.Linear(128, 32)\n",
        "        self.fc5 = nn.Linear(32, 10)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "\n",
        "        x = x.view(-1, 32*16*16)\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc5(x)\n",
        "        x = torch.log_softmax(x, dim=1)\n",
        "        return x\n",
        "    \n",
        "cnn = CNN()\n",
        "# Set device to GPU\n",
        "cnn.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vp6BLozdeW0"
      },
      "source": [
        "##### Train network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "EzJHXoOFdeW0"
      },
      "outputs": [],
      "source": [
        "# Train network\n",
        "# !pip install avalanche-lib[all]\n",
        "\n",
        "# from avalanche.benchmarks.classic import PermutedMNIST\n",
        "\n",
        "\n",
        "def train(dataset_no):\n",
        "    running_loss = 0.0\n",
        "    for epoch in range(1):  # loop over the dataset multiple times\n",
        "        for i, data in enumerate(train_dataload[dataset_no], 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            labels = labels + 2*dataset_no\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = cnn(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 0:    # print every batch size\n",
        "                print(f'[{dataset_no}, {epoch}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "    # Save model\n",
        "    PATH = './CNN_model'\n",
        "    torch.save(cnn.state_dict(), PATH)\n",
        "    \n",
        "    print('Finished Training dataset: ' + str(dataset_no))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "anU0q8k6ov2I"
      },
      "outputs": [],
      "source": [
        "def test(dataset_no): \n",
        "  # Test images\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for data in test_dataload[dataset_no]:\n",
        "          inputs, labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          # calculate outputs by running images through the network\n",
        "          outputs = cnn(inputs)\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "ZJbB222L976s"
      },
      "outputs": [],
      "source": [
        "# Test some images\n",
        "def test_show(dataset_no):\n",
        "    dataiter = iter(test_dataload[dataset_no])\n",
        "    inputs, labels = next(dataiter)\n",
        "\n",
        "    print('GroundTruth: ', ' '.join(f'{labels[j]:5}' for j in range(batch_size)))\n",
        "\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = cnn(inputs)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    print('Predicted: ', ' '.join(f'{predicted[j]:5}'for j in range(batch_size)))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FFKpP7xdeW0",
        "outputId": "3c28afc4-34d8-4f1a-f722-4f05e90a4c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0,     1] loss: 0.001\n",
            "[0, 0,   101] loss: 0.070\n",
            "[0, 0,   201] loss: 0.031\n",
            "[0, 0,   301] loss: 0.023\n",
            "[0, 0,   401] loss: 0.020\n",
            "[0, 0,   501] loss: 0.019\n",
            "[0, 0,   601] loss: 0.019\n",
            "[0, 0,   701] loss: 0.016\n",
            "[0, 0,   801] loss: 0.015\n",
            "[0, 0,   901] loss: 0.015\n",
            "Finished Training dataset: 0\n",
            "Accuracy of the network on the test images: 17 %\n",
            "GroundTruth:      3     4     3     4     2     3     2     0\n",
            "Predicted:      0     0     0     1     1     0     0     0\n",
            "[1, 0,     1] loss: 0.004\n",
            "[1, 0,   101] loss: 0.074\n",
            "[1, 0,   201] loss: 0.037\n",
            "[1, 0,   301] loss: 0.035\n",
            "[1, 0,   401] loss: 0.035\n",
            "[1, 0,   501] loss: 0.033\n",
            "[1, 0,   601] loss: 0.031\n",
            "[1, 0,   701] loss: 0.030\n",
            "[1, 0,   801] loss: 0.028\n",
            "[1, 0,   901] loss: 0.027\n",
            "Finished Training dataset: 1\n",
            "Accuracy of the network on the test images: 14 %\n",
            "GroundTruth:      1     4     1     7     1     9     9     7\n",
            "Predicted:      2     2     3     2     3     3     3     3\n",
            "[2, 0,     1] loss: 0.004\n",
            "[2, 0,   101] loss: 0.111\n",
            "[2, 0,   201] loss: 0.038\n",
            "[2, 0,   301] loss: 0.031\n",
            "[2, 0,   401] loss: 0.029\n",
            "[2, 0,   501] loss: 0.025\n",
            "[2, 0,   601] loss: 0.026\n",
            "[2, 0,   701] loss: 0.026\n",
            "[2, 0,   801] loss: 0.024\n",
            "[2, 0,   901] loss: 0.024\n",
            "Finished Training dataset: 2\n",
            "Accuracy of the network on the test images: 16 %\n",
            "GroundTruth:      9     2     8     6     5     3     3     5\n",
            "Predicted:      5     4     4     5     5     5     5     5\n",
            "[3, 0,     1] loss: 0.005\n",
            "[3, 0,   101] loss: 0.101\n",
            "[3, 0,   201] loss: 0.036\n",
            "[3, 0,   301] loss: 0.035\n",
            "[3, 0,   401] loss: 0.034\n",
            "[3, 0,   501] loss: 0.029\n",
            "[3, 0,   601] loss: 0.021\n",
            "[3, 0,   701] loss: 0.021\n",
            "[3, 0,   801] loss: 0.016\n",
            "[3, 0,   901] loss: 0.017\n",
            "Finished Training dataset: 3\n",
            "Accuracy of the network on the test images: 16 %\n",
            "GroundTruth:      2     6     1     2     7     6     7     5\n",
            "Predicted:      6     6     6     7     7     6     6     6\n",
            "[4, 0,     1] loss: 0.005\n",
            "[4, 0,   101] loss: 0.107\n",
            "[4, 0,   201] loss: 0.036\n",
            "[4, 0,   301] loss: 0.036\n",
            "[4, 0,   401] loss: 0.032\n",
            "[4, 0,   501] loss: 0.025\n",
            "[4, 0,   601] loss: 0.022\n",
            "[4, 0,   701] loss: 0.016\n",
            "[4, 0,   801] loss: 0.016\n",
            "[4, 0,   901] loss: 0.017\n",
            "Finished Training dataset: 4\n",
            "Accuracy of the network on the test images: 16 %\n",
            "GroundTruth:      2     4     3     4     2     4     9     8\n",
            "Predicted:      9     9     8     8     9     8     9     8\n"
          ]
        }
      ],
      "source": [
        "for x in range(5):\n",
        "    train(x)\n",
        "    test(x)\n",
        "    test_show(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkWzjp29993r"
      },
      "source": [
        "Test if model is working"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}